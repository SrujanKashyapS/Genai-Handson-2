{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-I_vQDuWp8h"
      },
      "source": [
        "---\n",
        "\n"
      ],
      "id": "h-I_vQDuWp8h"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_JyB2uZWp8j"
      },
      "source": [
        "# Unit 2 - Part 2a: The Anatomy of a Prompt\n",
        "\n",
        "## 1. Introduction: Stochasticity (Randomness)\n",
        "\n",
        "Why does the AI give different answers? Because it is **Stochastic** (Random).\n",
        "\n",
        "It predicts the NEXT TOKEN based on probability.\n",
        "\n",
        "### Visualizing the Prediction\n",
        "Input: `\"The sky is...\"`\n",
        "\n",
        "| Word | Probability | Selected? (Temp=0) | Selected? (Temp=1) |\n",
        "|------|-------------|--------------------|--------------------|\n",
        "| Blue | 80% | ✅ | ❌ |\n",
        "| Gray | 15% | ❌ | ✅ |\n",
        "| Green| 1% | ❌ | ❌ |\n",
        "\n",
        "Prompt Engineering is the art of **manipulating these probabilities**."
      ],
      "id": "k_JyB2uZWp8j"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDOcF38TWuEb",
        "outputId": "e980aa72-f7d6-4a22-aa2c-15af8ade480e"
      },
      "id": "UDOcF38TWuEb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m102.4/111.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1ea88321",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ea88321",
        "outputId": "8afa2f07-84e7-483f-c3cc-b51f5f3bea5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "# Using Low Temp for consistent comparison\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b87b7d",
      "metadata": {
        "id": "79b87b7d"
      },
      "source": [
        "## 2. The CO-STAR Framework (simplified)\n",
        "\n",
        "A good prompt usually has:\n",
        "1.  **C**ontext (Who are you? Who acts?)\n",
        "2.  **O**bjective (What is the task?)\n",
        "3.  **S**tyle (Formal? Funny?)\n",
        "4.  **T**one (Empathetic? Direct?)\n",
        "5.  **A**udience (Who is reading this?)\n",
        "6.  **R**esponse Format (JSON? List?)\n",
        "\n",
        "Let's compare a **Lazy Prompt** vs a **CO-STAR Prompt**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d6811389",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6811389",
        "outputId": "f4aa1c47-53ca-434e-9bf7-fc63935fd3fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAZY PROMPT ---\n",
            "Here are a few options for a rejection email, ranging from a standard template to one for a candidate who interviewed. Choose the one that best fits your situation.\n",
            "\n",
            "---\n",
            "\n",
            "**Option 1: Standard Rejection (No Interview)**\n",
            "\n",
            "This is suitable for candidates who applied but were not selected for an interview.\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to submit your application.\n",
            "\n",
            "We received a large number of highly qualified applications for this role. While your qualifications are impressive, we have decided to move forward with other candidates whose profiles were a closer match for the specific requirements of this position at this time.\n",
            "\n",
            "We appreciate you considering [Company Name] as a potential employer and wish you the best of luck in your job search and future endeavors.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 2: Rejection After Interview(s)**\n",
            "\n",
            "This option acknowledges the time and effort the candidate put into the interview process.\n",
            "\n",
            "**Subject: Update Regarding Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to interview with our team. We enjoyed learning more about your experience and qualifications.\n",
            "\n",
            "We appreciate you sharing your background and insights during our discussions. This was a highly competitive search, and we received applications from many talented individuals. After careful consideration, we have decided to move forward with another candidate whose qualifications and experience were a closer match for the specific needs of this role at this time.\n",
            "\n",
            "We truly appreciate your time and effort throughout the interview process. We wish you the very best in your job search and future career.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 3: Rejection with \"Keep on File\" Option (Use with Caution)**\n",
            "\n",
            "Only use this if you genuinely might consider them for future roles and have a system to track this.\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to apply/interview with us. We appreciate you sharing your background and experience.\n",
            "\n",
            "We received a significant number of applications for this role, and the selection process was highly competitive. While your qualifications are impressive, we have decided to move forward with another candidate whose profile was the best fit for our current needs.\n",
            "\n",
            "We were impressed with your [mention something general like \"experience\" or \"enthusiasm\"] and would like to keep your resume on file for future opportunities that may align more closely with your skills.\n",
            "\n",
            "We wish you the best of luck in your job search and future endeavors.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Key Considerations for Rejection Emails:**\n",
            "\n",
            "*   **Be Timely:** Send it as soon as a decision is made. Don't leave candidates hanging.\n",
            "*   **Be Clear and Direct:** Don't beat around the bush, but be polite.\n",
            "*   **Be Professional:** Maintain a positive image for your company.\n",
            "*   **Be Vague on Reasons:** Avoid giving specific reasons for rejection (e.g., \"you lacked X skill,\" \"your personality wasn't a fit\"). This can open the door to legal issues or arguments. Focus on the company's needs and the chosen candidate's \"closer match.\"\n",
            "*   **Personalize:** Always use the candidate's name.\n",
            "*   **Proofread:** Ensure there are no typos or grammatical errors.\n"
          ]
        }
      ],
      "source": [
        "# The Task: Reject a candidate for a job.\n",
        "task = \"Write a rejection email to a candidate.\"\n",
        "\n",
        "print(\"--- LAZY PROMPT ---\")\n",
        "print(llm.invoke(task).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f43fe6",
      "metadata": {
        "id": "48f43fe6"
      },
      "source": [
        "## 3. Hallucination vs. Creativity\n",
        "\n",
        "Did the model make up a reason?\n",
        "Since we didn't give it facts, it **Predicted the most likely reason** (Usually \"Experience\" or \"Volume of applications\").\n",
        "\n",
        "**This is NOT a bug.** It is a feature. The model is *completing the pattern* of a rejection email."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "727f0d12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727f0d12",
        "outputId": "03f60fa9-1403-43bc-97bf-875fbe4b4d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STRUCTURED PROMPT ---\n",
            "Hi Bob,\n",
            "\n",
            "Thank you for your interest in RocketBoots. We appreciate your time and effort.\n",
            "\n",
            "While your application was impressive, the requirements for this role have recently changed. We won't be moving forward with your candidacy at this time.\n",
            "\n",
            "Keep flying,\n",
            "RocketBoots HR\n"
          ]
        }
      ],
      "source": [
        "structured_prompt = \"\"\"\n",
        "# Context\n",
        "You are an HR Manager at a quirky startup called 'RocketBoots'.\n",
        "\n",
        "# Objective\n",
        "Write a rejection email to a candidate named Bob.\n",
        "\n",
        "# Constraints\n",
        "1. Be extremely brief (under 50 words).\n",
        "2. Do NOT say 'we found someone better'. Say 'the role changed'.\n",
        "3. Sign off with 'Keep flying'.\n",
        "\n",
        "# Output Format\n",
        "Plain text, no subject line.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- STRUCTURED PROMPT ---\")\n",
        "print(llm.invoke(structured_prompt).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886fa865",
      "metadata": {
        "id": "886fa865"
      },
      "source": [
        "## 4. Key Takeaway: Ambiguity is the Enemy\n",
        "\n",
        "Every piece of information you leave out is a gap the model MUST fill with probability.\n",
        "- If you don't say \"Be brief\", it picks the most probable length (Avg email length).\n",
        "- If you don't say \"Be rude\", it picks the most probable tone (Polite/Neutral)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3478f89a",
      "metadata": {
        "id": "3478f89a"
      },
      "source": [
        "## Assignment\n",
        "\n",
        "Write a structured prompt to generate a **Python Function**.\n",
        "- **Context:** You are a Senior Python Dev.\n",
        "- **Objective:** Write a function to reverse a string.\n",
        "- **Constraint:** It must use recursion (no slicing `[::-1]`).\n",
        "- **Style:** Include detailed docstrings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318d23f4",
      "metadata": {
        "id": "318d23f4"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd553194",
      "metadata": {
        "id": "fd553194"
      },
      "source": [
        "# Unit 2 - Part 2b: Zero-Shot to Few-Shot\n",
        "\n",
        "## 1. Introduction: In-Context Learning\n",
        "\n",
        "How does the model learn without training?\n",
        "This is called **In-Context Learning**.\n",
        "\n",
        "### The Attention Mechanism (Flowchart)\n",
        "When you ask a question, the model \"looks back\" at the previous text to find patterns.\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    Input[Current Input: 'Angry + Hungry'] -->|Attention Query| History\n",
        "    subgraph History [The Prompt Examples]\n",
        "        Ex1[Ex1: Breakfast + Lunch = Brunch]\n",
        "        Ex2[Ex2: Chill + Relax = Chillax]\n",
        "    end\n",
        "    History -->|Pattern Found: Mix words & define| Prediction[Output: Hangry]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "02843dde",
      "metadata": {
        "id": "02843dde"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70b5d34d",
      "metadata": {
        "id": "70b5d34d"
      },
      "source": [
        "## 2. Zero-Shot (No Context)\n",
        "\n",
        "The model relies purely on its training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d7781341",
      "metadata": {
        "id": "d7781341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50953d5a-d801-41c7-e4b7-523e089d64ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot: The most common and widely accepted funny word for this is:\n",
            "\n",
            "**Hangry**\n",
            "\n",
            "It's a perfect blend and very descriptive!\n",
            "\n",
            "If you're looking for something *else* (since \"hangry\" is already pretty common), here are a couple more ideas:\n",
            "\n",
            "*   **Grangry** (combining the \"grrr\" sound from both, suggesting a growl of frustration and hunger)\n",
            "*   **Rangry** (blends \"rage\" with \"hungry,\" implying anger fueled by an empty stomach)\n"
          ]
        }
      ],
      "source": [
        "prompt_zero = \"Combine 'Angry' and 'Hungry' into a funny new word.\"\n",
        "print(f\"Zero-Shot: {llm.invoke(prompt_zero).content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6c1820",
      "metadata": {
        "id": "9b6c1820"
      },
      "source": [
        "## 3. Few-Shot (Pattern Matching)\n",
        "\n",
        "We provide examples. The Attention Mechanism attends to the **Structure** (`Input -> Output`) and the **Tone** (Sarcasm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "832f1788",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832f1788",
        "outputId": "6bdc387e-23b7-434e-d522-f1a6c15d73cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-shot: Output: Hangry\n"
          ]
        }
      ],
      "source": [
        "prompt_few = \"\"\"\n",
        "Combine two words into a creative blended word.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Words: cold + coffee\n",
        "Output: Coffreeze\n",
        "\n",
        "Words: smoke + fog\n",
        "Output: Smog\n",
        "\n",
        "Words: breakfast + lunch\n",
        "Output: Brunch\n",
        "\n",
        "Now combine:\n",
        "\n",
        "Words: angry + hungry\n",
        "Output:\n",
        "\"\"\"\n",
        "\n",
        "print(\"Few-shot:\", llm.invoke(prompt_few).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "306a3c66",
      "metadata": {
        "id": "306a3c66"
      },
      "source": [
        "## 4. Critical Analysis\n",
        "\n",
        "If you provide **bad examples**, the model will learn the **bad pattern**.\n",
        "This is why Data Quality in your prompt is just as important as code quality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0583ce42",
      "metadata": {
        "id": "0583ce42"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad369bc1",
      "metadata": {
        "id": "ad369bc1"
      },
      "source": [
        "# Unit 2 - Part 2c: Advanced Templates & Theory\n",
        "\n",
        "## 1. Theory: Engineering vs. Training\n",
        "\n",
        "### Hard Prompts (Prompt Engineering)\n",
        "- **What:** You change the text input.\n",
        "- **Cost:** Cheap, fast, easy to iterate.\n",
        "- **Use Case:** Prototyping, General tasks.\n",
        "\n",
        "### Soft Prompts (Fine Tuning)\n",
        "- **What:** You change the model's internal weights (mathematically).\n",
        "- **Cost:** Expensive, slow, needs data.\n",
        "- **Use Case:** Domain specificity (Medical, Legal), Behavioral change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "2ec94769",
      "metadata": {
        "id": "2ec94769"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e03e7b",
      "metadata": {
        "id": "b1e03e7b"
      },
      "source": [
        "## 2. Dynamic Few-Shotting\n",
        "\n",
        "If you have 1000 examples, you can't fit them all in the context window.\n",
        "We use a **Selector** to pick the best ones.\n",
        "\n",
        "### The Selector Flow (Flowchart)\n",
        "```mermaid\n",
        "graph LR\n",
        "    Input[User Input] -->|Semantic Search| Database[Example Database]\n",
        "    Database -->|Top 3 Matches| Selector\n",
        "    Selector -->|Inject| Prompt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "30c20758",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30c20758",
        "outputId": "9dd70a64-9d68-4114-827e-de63ecd77b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "App-tagonistic – A playful blend of \"app\" and \"antagonistic,\" describing a digital tool that actively works against a smooth or positive user experience.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# Format of each example\n",
        "example_fmt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\")\n",
        "])\n",
        "\n",
        "# Example database\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"I want to stay in bed all day but I also feel guilty for being unproductive.\",\n",
        "        \"output\": \"Restlessponsible – A blended term describing the conflict between craving rest and feeling responsible for unfinished tasks.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"She keeps checking her phone even though she knows no new messages have arrived.\",\n",
        "        \"output\": \"Notifxious – A playful blend capturing the anxious anticipation of notifications that may not exist.\"\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"He laughed at the joke but deep down he was slightly offended.\",\n",
        "        \"output\": \"Laughended – A creative expression describing the awkward mix of amusement and mild offense.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_fmt,\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "final_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a Corpo-Speak Translator\"),\n",
        "    few_shot_prompt,\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "chain = final_prompt | llm\n",
        "\n",
        "print(chain.invoke({\"text\": \"This app is annoying .\"}).content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSo0QupoWp8p"
      },
      "source": [
        "## 3. Analysis\n",
        "\n",
        "Using `FewShotChatMessagePromptTemplate` creates a clean separation between instructions and data. This helps the Attention Mechanism focus on the right things."
      ],
      "id": "uSo0QupoWp8p"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "structured_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"You are a Principal Python Engineer who writes highly maintainable, \"\n",
        "     \"well-tested, production-grade Python code with strong type hints.\"),\n",
        "\n",
        "    (\"human\",\n",
        "     \"Implement a Python function that reverses a string.\\n\\n\"\n",
        "     \"Technical Requirements:\\n\"\n",
        "     \"- You MUST use recursion\\n\"\n",
        "     \"- You MUST NOT use slicing\\n\"\n",
        "     \"- Do not use built-in reverse utilities\\n\"\n",
        "     \"- Include type hints\\n\"\n",
        "     \"- Handle edge cases properly\\n\\n\"\n",
        "     \"Code Quality Requirements:\\n\"\n",
        "     \"- Add comprehensive docstrings (Google style)\\n\"\n",
        "     \"- Keep it clean and readable\\n\"\n",
        "     \"- Follow PEP8 standards\\n\"\n",
        "     \"- Include example usage\")\n",
        "])\n",
        "\n",
        "chain = structured_prompt | llm\n",
        "\n",
        "print(chain.invoke({}).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01WqwgOaZPmx",
        "outputId": "91f46c8f-e3c6-4cf8-cfc4-89ff0ea7e139"
      },
      "id": "01WqwgOaZPmx",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To implement a string reversal function using recursion, without slicing or built-in utilities, and adhering to strict quality requirements, we'll follow a classic recursive pattern. The core idea is to take the first character of the string, recursively reverse the rest of the string, and then append the first character to the end of the recursively reversed part.\n",
            "\n",
            "Since Python strings are immutable and we cannot use slicing (e.g., `s[1:]`), we'll use a helper function that takes the original string and a `current_index`. This helper will recursively call itself with `current_index + 1` until it reaches the end of the string, then build the reversed string by concatenating characters in reverse order of their original position.\n",
            "\n",
            "```python\n",
            "\"\"\"\n",
            "This module provides a recursive function to reverse a string.\n",
            "\"\"\"\n",
            "\n",
            "def reverse_string(s: str) -> str:\n",
            "    \"\"\"Reverses a string using recursion without slicing or built-in utilities.\n",
            "\n",
            "    This function takes a string `s` and returns a new string that is the\n",
            "    reverse of `s`. It achieves this by recursively processing the string\n",
            "    character by character. In each recursive step, it processes the remainder\n",
            "    of the string and then appends the current character to the end of the\n",
            "    result from the recursive call.\n",
            "\n",
            "    Args:\n",
            "        s: The input string to be reversed.\n",
            "\n",
            "    Returns:\n",
            "        The reversed string.\n",
            "\n",
            "    Raises:\n",
            "        TypeError: If the input `s` is not a string.\n",
            "\n",
            "    Examples:\n",
            "        >>> reverse_string(\"hello\")\n",
            "        'olleh'\n",
            "        >>> reverse_string(\"Python\")\n",
            "        'nohtyP'\n",
            "        >>> reverse_string(\"\")\n",
            "        ''\n",
            "        >>> reverse_string(\"a\")\n",
            "        'a'\n",
            "        >>> reverse_string(\"racecar\")\n",
            "        'racecar'\n",
            "    \"\"\"\n",
            "    # Type checking for robust error handling, even with type hints.\n",
            "    if not isinstance(s, str):\n",
            "        raise TypeError(\"Input must be a string.\")\n",
            "\n",
            "    # Define a nested helper function to perform the actual recursion.\n",
            "    # This closure allows it to access 's' from the outer scope without\n",
            "    # needing to pass 's' explicitly in each recursive call.\n",
            "    def _recursive_reverse_helper(current_index: int) -> str:\n",
            "        \"\"\"Helper function for `reverse_string` to perform the recursive logic.\n",
            "\n",
            "        Args:\n",
            "            current_index: The index of the character currently being processed\n",
            "                           in the original string `s`.\n",
            "\n",
            "        Returns:\n",
            "            The recursively reversed part of the string starting from `current_index`.\n",
            "        \"\"\"\n",
            "        # Base case:\n",
            "        # If the current_index has reached or surpassed the length of the string,\n",
            "        # it means all characters have been processed. Return an empty string\n",
            "        # as the foundation for concatenations.\n",
            "        # This handles empty strings, single-character strings, and the end\n",
            "        # of longer strings correctly.\n",
            "        if current_index >= len(s):\n",
            "            return \"\"\n",
            "        \n",
            "        # Recursive step:\n",
            "        # 1. Make a recursive call to process the \"rest\" of the string,\n",
            "        #    starting from the next character (current_index + 1).\n",
            "        #    This call will eventually return the reversed suffix of the string.\n",
            "        # 2. Append the character at the `current_index` (which is the \"first\"\n",
            "        #    character of the current subproblem) to the *end* of the result\n",
            "        #    from step 1. This effectively moves the first character to its\n",
            "        #    final reversed position.\n",
            "        return _recursive_reverse_helper(current_index + 1) + s[current_index]\n",
            "\n",
            "    # Start the recursion from the first character of the string (index 0).\n",
            "    return _recursive_reverse_helper(0)\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    print(\"--- Example Usage ---\")\n",
            "    \n",
            "    # Test cases\n",
            "    test_strings = [\n",
            "        \"hello\",\n",
            "        \"Python\",\n",
            "        \"\",\n",
            "        \"a\",\n",
            "        \"racecar\",\n",
            "        \"madam\",\n",
            "        \"level\"\n",
            "    ]\n",
            "\n",
            "    for test_str in test_strings:\n",
            "        reversed_str = reverse_string(test_str)\n",
            "        print(f\"'{test_str}' reversed is: '{reversed_str}'\")\n",
            "\n",
            "    print(\"\\n--- Edge Case Handling ---\")\n",
            "\n",
            "    # Test with non-string inputs to verify TypeError\n",
            "    try:\n",
            "        # Mypy will flag this as a type error, but we're intentionally testing runtime behavior\n",
            "        print(f\"123 reversed: {reverse_string(123)}\")  # type: ignore\n",
            "    except TypeError as e:\n",
            "        print(f\"Caught expected error for integer input: {e}\")\n",
            "\n",
            "    try:\n",
            "        # Mypy will flag this as a type error, but we're intentionally testing runtime behavior\n",
            "        print(f\"None reversed: {reverse_string(None)}\")  # type: ignore\n",
            "    except TypeError as e:\n",
            "        print(f\"Caught expected error for None input: {e}\")\n",
            "\n",
            "    # Note on recursion limit: Python has a default recursion limit (often 1000).\n",
            "    # For extremely long strings, this recursive approach might hit that limit.\n",
            "    # For competitive programming or specific scenarios, the limit can be increased:\n",
            "    # import sys\n",
            "    # sys.setrecursionlimit(2000) # Example: set to 2000\n",
            "    # long_string = \"x\" * 1500\n",
            "    # print(f\"\\nLong string ('x'*1500) reversed (first 10 chars): {reverse_string(long_string)[:10]}...\")\n",
            "```\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}